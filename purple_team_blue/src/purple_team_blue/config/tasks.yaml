

analyze_threat_requirements:
  description: >
    Read and analyse the threat intel report provided with the RAG tool at your disposal.
    2. Extract the two most significant TTPS (or ATT&CK IDs) for the behaviors described in the threat intel report.
    3. Then, learn more about these two TTPS by reading through the relevant pages on the official MITRE website (and if needed, other authoritative websites).
    4. Deconstruct it into its core components. Identify common processes, command-line arguments,
      parent processes, registry keys, file paths, and the attacker's primary objective.
    This includes:
    
    1. Threat Classification:
       - Identify ONLY ONE of the described threat types (malware, technique, behavior)
       - Map it to one or more relevant MITRE ATT&CK IDs
       - Determine threat severity level
    
    2. Data Source Analysis:
       - Identify optimal log sources for detection
       - Determine required log fields and event types
       - Consider multiple detection approaches if applicable
    
    3. Detection Strategy:
       - Define detection approach (signature-based, behavioral, statistical)
       - Identify key indicators and artifacts
       - Consider evasion techniques and variants

    **IMPORTANT:** If your tool for finding the current date fails, use today's
     date, September 23, 2025, as a fallback. Do not get stuck. Acknowledge the
     tool failure and proceed with the rest of the task using this fallback date.
    
  expected_output: >
    A comprehensive threat analysis brief in structured format including:
    - Threat classification and MITRE ATT&CK mapping
    - Recommended data sources and log types
    - Detection strategy and key indicators  
    - Scope definition and environmental considerations
    - Specific fields and values to monitor
  agent: threat_analyst_agent
  

create_rule_metadata:
  description: >
    Generate comprehensive metadata for the Sigma rule based on the threat analysis brief.
    
    Required metadata elements:
    1. Title: Descriptive, specific title following naming conventions
    2. ID: UUID4 identifier for the rule
    3. Status: Rule maturity level (experimental, test, stable)
    4. Description: Detailed description of what the rule detects
    5. References: Relevant threat intelligence, CVEs, or research links
    6. Author: Rule author information
    7. Date: Creation/modification dates
    8. Modified: Last modification date
    9. Tags: Relevant categorization tags
    10. Level: Severity level (low, medium, high, critical)
    11. MITRE ATT&CK: Technique and tactic mappings
    12. Logsource: Target log source specification (usually it's Windows)
    
    Ensure all metadata follows Sigma rule standards and provides sufficient context 
    for analysts and rule management systems.

  expected_output: >
    Complete Sigma rule metadata section in valid YAML format, including:
    - All required metadata fields properly formatted
    - Accurate MITRE ATT&CK technique mappings
    - Appropriate severity level and tags
    - Proper logsource specification
    - UUID4 identifier and timestamps
  agent: metadata_specialist_agent
  context: 
    - analyze_threat_requirements


develop_detection_logic:
  description: >
    Create the complete detection section of the Sigma rule, including selections, 
    filters, and condition logic. This task requires careful coordination of all 
    detection components with special attention to Living Off The Land techniques 
    and legitimate system tool usage patterns.
    
    Components to develop:
    1. Selection Blocks:
       - Define base selections with appropriate field mappings
       - Create variant selections for different attack methods
       - Include LOLBins-specific detection patterns when applicable
       - Ensure proper field naming and value matching
    
    2. Filter Logic:
       - Identify legitimate activities to exclude (especially common admin tasks)
       - Create negative filters to reduce false positives
       - Consider time-based or conditional filtering
       - Account for legitimate LOLBins usage scenarios
    
    3. Condition Statement:
       - Combine selections and filters logically
       - Use appropriate boolean operators (and, or, not)
       - Optimize for performance and accuracy
       - Balance detection coverage with false positive risk
    
    4. Field Specification:
       - List key fields for analyst review
       - Ensure fields align with detection logic
       - Prioritize most relevant investigative fields
       - Include process ancestry and command-line details for LOLBins cases
    
    5. LOLBins Considerations:
       - Identify if the threat involves abuse of legitimate system tools
       - Implement detection patterns that focus on malicious usage indicators
       - Consider parent-child process relationships
       - Analyze command-line arguments and parameters
       - Factor in file locations and network connections
       - Account for normal administrative usage patterns
    
    Technical Requirements:
    - Use proper Sigma syntax and field mappings
    - Consider case sensitivity and wildcards appropriately
    - Optimize for performance while maintaining accuracy
    - Ensure compatibility with common SIEM platforms
    - Implement LOLBins detection best practices when applicable
    
  expected_output: >
    Complete detection section in valid Sigma YAML format containing:
    - Well-structured selection blocks with proper field mappings
    - LOLBins-aware detection patterns when applicable
    - Appropriate filter logic to minimize false positives from legitimate admin activities
    - Logical condition statement combining all elements effectively
    - Relevant fields list for analyst investigation including process details
    - Syntactically correct and performant detection logic
    - Clear documentation of LOLBins techniques addressed (if applicable)
  agent: detection_logic_engineer
  context:
    - analyze_threat_requirements
    - create_rule_metadata



analyze_false_positives:
  description: >
    Conduct thorough analysis to identify potential false positive scenarios based 
    on real-world Windows system administration and DevOps experience. Leverage 
    deep knowledge of legitimate system operations, scheduled tasks, service accounts, 
    and administrative workflows.
    
    Analysis Areas:
    1. System Administration Activities:
       - Daily/weekly/monthly administrative tasks and their timing
       - Patch management and Windows Update processes
       - Backup and restore operations (including PowerShell-based)
       - Group Policy updates and Active Directory maintenance
       - Certificate management and renewal processes
       - Service account operations and scheduled tasks
    
    2. DevOps and Automation:
       - CI/CD pipeline activities and deployment scripts
       - Infrastructure as Code (PowerShell DSC, Ansible, etc.)
       - Monitoring and alerting scripts
       - Configuration management activities
       - Automated testing and validation scripts
    
    3. Legitimate Tool Usage (LOLBins Context):
       - Normal administrative use of PowerShell, WMI, certutil, etc.
       - Software installation and configuration processes
       - System troubleshooting and diagnostic activities
       - Network connectivity testing and validation
       - File transfer and synchronization operations
    
    4. Environmental and Temporal Factors:
       - Business hours vs. maintenance windows
       - User context (admin accounts vs. service accounts vs. regular users)
       - Domain-joined vs. workgroup systems
       - Server roles and their typical behaviors
       - Geographic and time zone considerations
    
    5. Service Account and System Behaviors:
       - Scheduled task execution patterns
       - Service startup and shutdown sequences
       - System service communications
       - Antivirus and security tool operations
       - Backup agent and monitoring tool activities
    
    6. Real-World Tuning Recommendations:
       - Specific exclusions based on user accounts or groups
       - Time-based filtering for maintenance windows
       - Process ancestry checks to validate legitimate context
       - Command-line argument filtering for known admin tools
       - Network source/destination filtering for internal operations
    
    Provide actionable, specific recommendations that reflect real-world system 
    administration experience and practical knowledge of how Windows environments 
    actually operate in enterprise settings.
    
    Input: Validated Sigma rule and threat analysis brief
    
    Output: Comprehensive false positive analysis with practical tuning recommendations
  expected_output: >
    Detailed false positive analysis document containing:
    - Categorized list of realistic false positive scenarios based on sysadmin experience
    - Specific examples of legitimate Windows operations that might trigger the rule
    - Timing-based considerations (maintenance windows, business hours, patch cycles)
    - Service account and automation-related false positives
    - LOLBins legitimate usage scenarios and how to distinguish them
    - Practical filtering recommendations with specific Sigma syntax examples
    - Environmental tuning guidance for different Windows deployment scenarios
    - Escalation procedures and analyst guidance for investigating triggered alerts
    - Risk assessment for each identified false positive category with mitigation strategies
  agent: false_positives_analyst
  async_execution: false
  context:
    - analyze_threat_requirements
    - develop_detection_logic
  dependencies:
    - develop_detection_logic


generate_atomic_sigma_rules:
  description: >
    Critically analyze all provided threat intelligence and detection logic to create a set of ATOMIC, HIGH-FIDELITY Sigma rules. 
    Your goal is to produce multiple, focused rules, not one large, monolithic rule. 
    Each rule must target a single, specific attacker behavior to ensure it is precise and has a low false-positive rate.

    Core Principles for Rule Creation:
    1. Deconstruct and Isolate Behaviors:
        - Review the threat analysis and drafted logic to identify distinct stages or techniques (TTPs).
        - Examples of distinct behaviors to isolate:
            - Initial Access: Phishing link click leading to a suspicious network connection.
            - Execution: Payload download via a specific LOLBin (e.g., certutil, bitsadmin).
            - Discovery (Local): Enumeration of local users and groups (`net user`, `whoami /groups`).
            - Discovery (Domain): Broad enumeration of domain objects (`dsquery`, `Get-ADUser -Filter *`).
            - Tooling: Execution of a known offensive security tool (`SharpHound`, `Rubeus`).

    2. One Rule Per Behavior:
        - For EACH distinct behavior identified, you must generate a completely separate and self-contained Sigma rule file.
        - DO NOT combine unrelated activities (like a download AND discovery) into a single rule.

    3. Engineer for High Fidelity (Low Noise):
      - Simple & Logical Conditions: The 'condition' field in each rule must be straightforward (e.g., `selection and not filter`). 
        Avoid complex `or` chains that mix different event types.
      - Robust Indicators: Prioritize strong, context-rich indicators over fragile ones. For example, favor specific
        command-line argument patterns over a simple process name that can be easily changed.
      - Targeted Filtering: Each atomic rule must have its own specific filters designed to weed out false positives 
        FOR THAT SPECIFIC BEHAVIOR. Filters for a network rule are different from filters for a process rule.

    Other instructions:
    - Ensure the detection field is a dictionary where keys are search identifiers (like 'selection') 
      and their values are lists of dictionaries or simple dictionaries defining the criteria.
    - Remember to call the Sigma Rule Structuring Tool with all the necessary fields from the rule you have developed.

  expected_output: >
    A final response containing a collection of multiple, separate Sigma rules in YAML format. Each rule must be atomic, targeting one specific behavior, 
    and meticulously engineered with targeted filters to ensure a high signal-to-noise ratio and production-readiness.
  agent: principal_detection_engineer
  async_execution: false
  context:
    - analyze_threat_requirements
    - create_rule_metadata
    - develop_detection_logic
    - analyze_false_positives
